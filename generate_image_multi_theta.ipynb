{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('tele_datasets\\Changing')\n",
    "\n",
    "output_dir = Path(r'tele_datasets\\mixed\\train\\images')\n",
    "txt_dir = Path(r'tele_datasets\\mixed\\train\\labels')\n",
    "\n",
    "noise_radius = 20\n",
    "# for i in root_dir.iterdir():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = list(root_dir.iterdir())\n",
    "theta_len = len(thetas)\n",
    "\n",
    "def get_image(image_name):\n",
    "    output_image = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    \n",
    "    for i in thetas:\n",
    "        image_dir = i / 'images'\n",
    "        image_lst = list(image_dir.iterdir())\n",
    "        image_path = np.random.choice(image_lst)\n",
    "        txt_path = image_path.parent.parent / 'labels' / f'{image_path.stem}.txt'\n",
    "        \n",
    "        # Read the txt file and merge it to a large txt file\n",
    "        with open(txt_path, 'r') as file:\n",
    "            txt_content = file.read()\n",
    "            with open((txt_dir / f'{image_name}.txt').as_posix(), 'a') as large_file:\n",
    "                large_file.write(txt_content)\n",
    "        \n",
    "        image_arr = cv2.imread(image_path.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
    "        output_image += image_arr\n",
    "\n",
    "    output_image = output_image.astype(np.int64)\n",
    "    noise_radius = np.random.randint(10, 30)\n",
    "    noise1 = np.random.normal(loc=0, scale=noise_radius, size=(1024, 1024))\n",
    "    noise2 = np.random.normal(loc=0, scale=noise_radius / 4, size=(512, 512))\n",
    "    noise2 = cv2.resize(noise2, (1024, 1024))\n",
    "    noisy_img = output_image + noise1 + noise2\n",
    "    noisy_img = np.where(noisy_img > 255, 255, noisy_img)\n",
    "    noisy_img = np.where(noisy_img < 0, 0, noisy_img)\n",
    "    noisy_img = noisy_img.astype(np.uint8)\n",
    "    img_path = (output_dir / f'{image_name}.png').as_posix()\n",
    "    # print(img_path)\n",
    "    cv2.imwrite(img_path, noisy_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 800\n",
    "for j in range(num_image):\n",
    "    get_image(j)\n",
    "with concurrent.futures.ProcessPoolExecutor(10) as executor:\n",
    "    executor.map(get_image, range(num_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(r'tele_datasets\\mixed\\validation\\images')\n",
    "txt_dir = Path(r'tele_datasets\\mixed\\validation\\labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = list(root_dir.iterdir())\n",
    "theta_len = len(thetas)\n",
    "\n",
    "def get_image(image_name):\n",
    "    output_image = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "    \n",
    "    for i in thetas:\n",
    "        image_dir = i / 'images'\n",
    "        image_lst = list(image_dir.iterdir())\n",
    "        image_path = np.random.choice(image_lst)\n",
    "        txt_path = image_path.parent.parent / 'labels' / f'{image_path.stem}.txt'\n",
    "        \n",
    "        # Read the txt file and merge it to a large txt file\n",
    "        with open(txt_path, 'r') as file:\n",
    "            txt_content = file.read()\n",
    "            with open((txt_dir / f'{image_name}.txt').as_posix(), 'a') as large_file:\n",
    "                large_file.write(txt_content)\n",
    "        \n",
    "        image_arr = cv2.imread(image_path.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
    "        output_image += image_arr\n",
    "\n",
    "    output_image = output_image.astype(np.int64)\n",
    "    noise_radius = np.random.randint(10, 30)\n",
    "    noise1 = np.random.normal(loc=0, scale=noise_radius, size=(1024, 1024))\n",
    "    noise2 = np.random.normal(loc=0, scale=noise_radius / 4, size=(512, 512))\n",
    "    noise2 = cv2.resize(noise2, (1024, 1024))\n",
    "    noisy_img = output_image + noise1 + noise2\n",
    "    noisy_img = np.where(noisy_img > 255, 255, noisy_img)\n",
    "    noisy_img = np.where(noisy_img < 0, 0, noisy_img)\n",
    "    noisy_img = noisy_img.astype(np.uint8)\n",
    "    img_path = (output_dir / f'{image_name}.png').as_posix()\n",
    "    # print(img_path)\n",
    "    cv2.imwrite(img_path, noisy_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 200\n",
    "for j in range(num_image):\n",
    "    get_image(j)\n",
    "with concurrent.futures.ProcessPoolExecutor(10) as executor:\n",
    "    executor.map(get_image, range(num_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
